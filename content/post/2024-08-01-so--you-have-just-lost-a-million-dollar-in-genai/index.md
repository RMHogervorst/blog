---
title: So you've just lost a million dollars in the genAI hype
description: ""
subtitle: what lessons can you learn?
date: 2024-08-01
preview: ""
tags:
    - LLMs
    - genAI
    - pseudoprofoundBS
categories:
    - blog
difficulty: 
    - beginner
post-type: 
    - thoughts
share_img: ""
image: ""
---

Hi C-level person! Are you feeling down because AI is not working for you? Let me know if this is you:

A smug consultant sold you a genAI solution. By now you've realised that **it doesn't work**, it **can not work** in theory and now it also doesn't work in practice. You still have data quality issues, and your promised profits are non-existing. Are there any lessons you can learn from this fiasco?

## the dream

![I've added a few inspiring images to rest your eyes in between the text, the content does not matter, think wide open spaces, staring people, feelings of awe](greg-rakozy-oMpAz-DN-9I-unsplash.jpg)

Ah it was so enticing! AI! just like the movies! sure it wasn't completely there yet, but the demos looked awesome! You bought in the hype. You looked at Gartner magic quadrants and thought AI was the going to be the future! You visited conferences, you read the articles. McKinsey told us AI would lead to 4.4 trillion in profits.

You evangalised the shit out of it, you said it would transform work, _but really you hoped you could use it to fire people ( awesome for stock prices! And therefore your payout)._ 
You invested a lot of money and wasted perfectly good engineering time. 

## Oh shit, there is no magic here

But now the tide is turning. Sure there were earlier signs, the academics that complained, _but they always do don't they?_ The data scientists tried to temper your expectations, _but they don't have vision like you do!_ 

- [Cory Doctorow talked about the hype before, but he is a scifi writer so who cares](https://locusmag.com/2023/12/commentary-cory-doctorow-what-kind-of-bubble-is-ai/)
- [Ed Zitron constantly complains about lack of actual results](https://www.wheresyoured.at/sam-altman-is-full-of-shit/)
- [Upwork tells us that managers expect productivity gains but employees are just burning out](https://www.upwork.com/research/ai-enhanced-work-models)

But oh no, you can no longer ignore the news, Venture capitalists are worried. Even Goldman-Sachs is saying genAI is dead! And they don't give a shit about anybody, they bribe, they work with dictators, they fuck up systems just to make money, they don't even care about their own employees! 

- [Goldman Sachs seriously tempers expectations of profit](https://www.goldmansachs.com/insights/top-of-mind/gen-ai-too-much-spend-too-little-benefit)
- even [venture capitalist are getting nervous](https://www.sequoiacap.com/article/ais-600b-question/)

## A post-mortem

As a C-level exec you would usually flee before the troubles start[^4], but you know maybe this time you won't or maybe it is already too late. You are responsible, so who knows, you might be held accountable for this fiasco[^1]!

Anyways, it is time for a post mortem. All the cool tech people do post-mortums on things that went wrong. And post-mortem is what you do on a dead body and boy is genAI dead.
What can we learn from this corpse? Here are some lessons I think you can learn from the freshly reeking genAI cadavre.

Pay attention to the professional grifters. Where they go, you should not. I'm talking about the AI guys, formerly the crypto guys, the dudes who will soon try to sell you post-quantum things (because genAI is dead)

When people try to sell you magic technology, ask difficult questions like: how will it increase my sales? Be specific, aks for here and now. Not in the future, but tomorrow, how will the magical device transform your work. Clear out when there are no technical insights, no specifics, and very few details.

There is no first mover advantage. Its just more work, more costs. So any appeal to 'be the first' or 'get in early' is junk. 

If someone proposes a solution that steals data all over the internet _(you think they payed anyone for their training data?)_, and generates bullshit _(this is the technical term; indifferent to the truth[^2])_, why would it be useful to you? When do you not care about truth?[^3] Are there applications where you are completely fine if the output is always made up? 

Solving business problems is hard work and requires good people and time. Machine learning solutions are not hard to make nowadays, but creating useful systems is very difficult. 

So maybe you have learned your lessons, and will apply them in the future and maybe you can let people like me work on the boring but actually valuable work. Transforming data, creating forecasts, predictions and making data available to who needs it. 


[^1]: who are we kidding, CEOs have never faced consequenses larger than a small reduction in your golden parachute.
[^2]: see [ChatGPT is bullshit](https://link.springer.com/article/10.1007/s10676-024-09775-5) in which they explain that because the system does not care about the truthfulness of its output, it is producing bullshit in the technical term as used by Frankfurt (On Bullshit, Princeton, 2005)
[^3]: Alright I can think of a few options; politics, crime and spam ( and many forms of marketing). If crime or spam is your business than you are in a golden time and you should ignore what I wrote, and you probably do.
[^4]: Or every 2 years, whichever comes first.

_image from [Greg Rakozy](https://unsplash.com/@grakozy) on [unsplash](https://unsplash.com/photos/silhouette-photography-of-person-oMpAz-DN-9I)_